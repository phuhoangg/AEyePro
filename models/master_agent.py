import asyncio
import json
import logging
from typing import Dict, List, Optional, Union, Any
from dataclasses import dataclass
from enum import Enum
import re
from datetime import datetime
from langchain.llms import LlamaCpp
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.schema import BaseMessage, HumanMessage, AIMessage
from models.recommend_agent import RecommendAgent
from models.retrieval_agent import RetrievalAgent
from core.health_data_collector import HealthDataCollector

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class AgentType(Enum):
    """ƒê·ªãnh nghƒ©a c√°c lo·∫°i sub-agent"""
    RECOMMEND = "recommend_agent"
    RETRIEVAL = "retrieval_agent"
    NONE = "none"
    GENERAL_CHAT = "general_chat"  # Th√™m lo·∫°i chat chung


@dataclass
class AgentResponse:
    """C·∫•u tr√∫c ph·∫£n h·ªìi t·ª´ sub-agent"""
    success: bool
    data: Optional[Dict] = None
    error: Optional[str] = None
    agent_type: Optional[AgentType] = None


@dataclass
class UserQuery:
    """C·∫•u tr√∫c c√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng"""
    text: str
    timestamp: datetime
    intent: Optional[str] = None
    entities: Optional[List[str]] = None


class SmartIntentClassifier:
    """Ph√¢n lo·∫°i √Ω ƒë·ªãnh th√¥ng minh v·ªõi kh·∫£ nƒÉng nh·∫≠n bi·∫øt c√¢u h·ªèi kh√¥ng li√™n quan"""

    def __init__(self):
        # T·ª´ kh√≥a ch√≠nh x√°c cho recommend_agent
        self.recommend_keywords = [
            "c·∫£nh b√°o", "alert", "khuy·∫øn ngh·ªã", "recommend", "hi·ªán t·∫°i", "b√¢y gi·ªù",
            "real-time", "th·ªùi gian th·ª±c", "t∆∞ th·∫ø", "posture", "m·∫Øt", "eye",
            "ngh·ªâ", "break", "ng·ªìi", "sitting", "l√†m vi·ªác", "work", "s·ª©c kh·ªèe",
            "health", "m·ªèi", "tired", "stress", "cƒÉng th·∫≥ng", "monitor", "theo d√µi",
            "start", "stop", "b·∫Øt ƒë·∫ßu", "d·ª´ng", "status", "tr·∫°ng th√°i"
        ]

        # T·ª´ kh√≥a ch√≠nh x√°c cho retrieval_agent
        self.retrieval_keywords = [
            "ph√¢n t√≠ch", "analysis", "xu h∆∞·ªõng", "trend", "l·ªãch s·ª≠", "history",
            "th·ªëng k√™", "statistic", "b√°o c√°o", "report", "so s√°nh", "compare",
            "tu·∫ßn", "week", "th√°ng", "month", "ng√†y", "day", "th·ªùi gian", "time",
            "hi·ªáu su·∫•t", "performance", "th√≥i quen", "habit", "pattern", "m·∫´u",
            "d·ªØ li·ªáu", "data", "t√¨m ki·∫øm", "search", "truy v·∫•n", "query",
            "bu·ªïi s√°ng", "morning", "bu·ªïi t·ªëi", "evening", "bu·ªïi chi·ªÅu", "afternoon"
        ]

        # T·ª´ kh√≥a cho c·∫£ hai agent
        self.both_keywords = [
            "t·ªïng h·ª£p", "overview", "t·ªïng quan", "general", "to√†n b·ªô", "all",
            "comprehensive", "chi ti·∫øt", "detailed", "full", "ƒë·∫ßy ƒë·ªß"
        ]

        # T·ª´ kh√≥a li√™n quan ƒë·∫øn s·ª©c kh·ªèe/l√†m vi·ªác - ch·ªâ nh·ªØng c√¢u c√≥ t·ª´ n√†y m·ªõi c·∫ßn sub-agent
        self.health_work_context = [
            "s·ª©c kh·ªèe", "health", "l√†m vi·ªác", "work", "ng·ªìi", "sitting",
            "m√°y t√≠nh", "computer", "vƒÉn ph√≤ng", "office", "m·∫Øt", "eye",
            "l∆∞ng", "back", "c·ªï", "neck", "t∆∞ th·∫ø", "posture", "m·ªèi", "tired",
            "ƒëau", "pain", "ngh·ªâ", "break", "gi·∫£i lao", "exercise", "th·ªÉ d·ª•c",
            "monitor", "theo d√µi", "tracking", "productivity", "nƒÉng su·∫•t"
        ]

        # T·ª´ kh√≥a chat chung - kh√¥ng c·∫ßn sub-agent
        self.general_chat_keywords = [
            "xin ch√†o", "hello", "hi", "ch√†o", "c·∫£m ∆°n", "thank", "t·∫°m bi·ªát", "bye",
            "th·ªùi ti·∫øt", "weather", "ƒÉn", "eat", "u·ªëng", "drink", "phim", "movie",
            "nh·∫°c", "music", "tin t·ª©c", "news", "b√≥ng ƒë√°", "football", "game",
            "h·ªçc", "study", "tr∆∞·ªùng", "school", "b·∫°n", "friend", "gia ƒë√¨nh", "family",
            "y√™u", "love", "vui", "happy", "bu·ªìn", "sad", "gi·∫£i tr√≠", "entertainment",
            "du l·ªãch", "travel", "mua s·∫Øm", "shopping", "n·∫•u ƒÉn", "cooking"
        ]

        # C√°c c√¢u h·ªèi th√¥ng th∆∞·ªùng kh√¥ng c·∫ßn sub-agent
        self.general_patterns = [
            r".*l√† g√¨.*",
            r".*how to.*",
            r".*c√°ch.*",
            r".*why.*",
            r".*t·∫°i sao.*",
            r".*ƒë·ªãnh nghƒ©a.*",
            r".*gi·∫£i th√≠ch.*",
            r".*explain.*",
            r".*what.*",
            r".*where.*",
            r".*when.*",
            r".*who.*"
        ]

    def classify_intent(self, query: str) -> Dict[str, Any]:
        """Ph√¢n lo·∫°i √Ω ƒë·ªãnh th√¥ng minh"""
        query_lower = query.lower()

        # B∆∞·ªõc 1: Ki·ªÉm tra ng·ªØ c·∫£nh s·ª©c kh·ªèe/c√¥ng vi·ªác
        has_health_context = any(keyword in query_lower for keyword in self.health_work_context)

        # B∆∞·ªõc 2: Ki·ªÉm tra c√¢u h·ªèi chat chung
        has_general_chat = any(keyword in query_lower for keyword in self.general_chat_keywords)

        # B∆∞·ªõc 3: Ki·ªÉm tra pattern c√¢u h·ªèi chung
        is_general_question = any(re.search(pattern, query_lower) for pattern in self.general_patterns)

        # B∆∞·ªõc 4: T√≠nh ƒëi·ªÉm cho c√°c agent
        recommend_score = sum(1 for keyword in self.recommend_keywords if keyword in query_lower)
        retrieval_score = sum(1 for keyword in self.retrieval_keywords if keyword in query_lower)
        both_score = sum(1 for keyword in self.both_keywords if keyword in query_lower)

        result = {
            "primary_agent": AgentType.NONE,
            "secondary_agent": None,
            "confidence": 0.0,
            "reasoning": "",
            "use_both": False,
            "use_general_chat": False,
            "has_health_context": has_health_context
        }

        # Logic quy·∫øt ƒë·ªãnh
        if has_general_chat and not has_health_context:
            result["use_general_chat"] = True
            result["primary_agent"] = AgentType.GENERAL_CHAT
            result["confidence"] = 0.9
            result["reasoning"] = "C√¢u h·ªèi chat chung, kh√¥ng c·∫ßn s·ª≠ d·ª•ng sub-agent"

        elif is_general_question and not has_health_context:
            result["use_general_chat"] = True
            result["primary_agent"] = AgentType.GENERAL_CHAT
            result["confidence"] = 0.8
            result["reasoning"] = "C√¢u h·ªèi th√¥ng th∆∞·ªùng, kh√¥ng li√™n quan ƒë·∫øn d·ªØ li·ªáu s·ª©c kh·ªèe"

        elif not has_health_context and recommend_score == 0 and retrieval_score == 0:
            result["use_general_chat"] = True
            result["primary_agent"] = AgentType.GENERAL_CHAT
            result["confidence"] = 0.7
            result["reasoning"] = "C√¢u h·ªèi kh√¥ng li√™n quan ƒë·∫øn s·ª©c kh·ªèe/c√¥ng vi·ªác"

        elif has_health_context:
            if both_score > 0 or abs(recommend_score - retrieval_score) <= 1:
                result["use_both"] = True
                result["primary_agent"] = AgentType.RECOMMEND
                result["secondary_agent"] = AgentType.RETRIEVAL
                result["confidence"] = 0.8
                result["reasoning"] = "C√¢u h·ªèi v·ªÅ s·ª©c kh·ªèe c·∫ßn th√¥ng tin t·ª´ c·∫£ hai agent"

            elif recommend_score > retrieval_score:
                result["primary_agent"] = AgentType.RECOMMEND
                result["confidence"] = min(recommend_score / 3.0, 1.0)
                result["reasoning"] = "C√¢u h·ªèi v·ªÅ c·∫£nh b√°o v√† khuy·∫øn ngh·ªã s·ª©c kh·ªèe"

            elif retrieval_score > recommend_score:
                result["primary_agent"] = AgentType.RETRIEVAL
                result["confidence"] = min(retrieval_score / 3.0, 1.0)
                result["reasoning"] = "C√¢u h·ªèi v·ªÅ ph√¢n t√≠ch d·ªØ li·ªáu s·ª©c kh·ªèe"

            else:
                result["primary_agent"] = AgentType.RECOMMEND
                result["confidence"] = 0.5
                result["reasoning"] = "C√¢u h·ªèi v·ªÅ s·ª©c kh·ªèe, s·ª≠ d·ª•ng recommend agent m·∫∑c ƒë·ªãnh"
        else:
            result["use_general_chat"] = True
            result["primary_agent"] = AgentType.GENERAL_CHAT
            result["confidence"] = 0.6
            result["reasoning"] = "Kh√¥ng th·ªÉ x√°c ƒë·ªãnh √Ω ƒë·ªãnh, s·ª≠ d·ª•ng chat chung"

        return result


class LLMResponseGenerator:
    """Sinh ph·∫£n h·ªìi s·ª≠ d·ª•ng LLM v·ªõi kh·∫£ nƒÉng chat chung"""

    def __init__(self, model_path: str = "models/Llama-3.2-3B-Instruct-Q8_0.gguf"):
        """Kh·ªüi t·∫°o LLM"""
        try:
            self.llm = LlamaCpp(
                model_path=model_path,
                n_gpu_layers=-1,
                temperature=0.7,
                max_tokens=512,
                n_ctx=2048,
                verbose=False
            )
            if self.llm is None:
                raise RuntimeError("LLM model not initialized. Ki·ªÉm tra l·∫°i file model ho·∫∑c c·∫•u h√¨nh m√°y.")

            self.synthesis_template = PromptTemplate(
                input_variables=["query", "agent_responses", "context"],
                template="""<|begin_of_text|><|start_header_id|>system<|end_header_id>
Cutting Knowledge Date: December 2023 Today Date: 26 Jul 2024

B·∫°n l√† m·ªôt AI Assistant chuy√™n nghi·ªáp h·ªó tr·ª£ theo d√µi s·ª©c kh·ªèe v√† ph√¢n t√≠ch d·ªØ li·ªáu. Nhi·ªám v·ª• c·ªßa b·∫°n l√†:

1. T·ªïng h·ª£p th√¥ng tin t·ª´ c√°c agent m·ªôt c√°ch r√µ r√†ng v√† h·ªØu √≠ch
2. ∆Øu ti√™n c·∫£nh b√°o s·ª©c kh·ªèe quan tr·ªçng
3. Gi·∫£i th√≠ch d·ªØ li·ªáu ph√¢n t√≠ch m·ªôt c√°ch d·ªÖ hi·ªÉu
4. S·ª≠ d·ª•ng emoji ph√π h·ª£p ƒë·ªÉ l√†m n·ªïi b·∫≠t th√¥ng tin
5. Tr√¨nh b√†y k·∫øt qu·∫£ v·ªõi ƒë·ªãnh d·∫°ng r√µ r√†ng, c√≥ d·∫•u c√°ch v√† xu·ªëng d√≤ng ph√π h·ª£p

Quy t·∫Øc tr√¨nh b√†y:
- S·ª≠ d·ª•ng **in ƒë·∫≠m** cho ti√™u ƒë·ªÅ v√† ƒëi·ªÉm quan tr·ªçng
- Th√™m d·∫•u c√°ch v√† xu·ªëng d√≤ng ƒë·ªÉ d·ªÖ ƒë·ªçc
- S·ª≠ d·ª•ng emoji ƒë·ªÉ ph√¢n lo·∫°i th√¥ng tin (‚ö†Ô∏è c·∫£nh b√°o, üìä ph√¢n t√≠ch, ‚úÖ b√¨nh th∆∞·ªùng, üîÑ h√†nh ƒë·ªông)
- Kh√¥ng l·∫∑p l·∫°i th√¥ng tin kh√¥ng c·∫ßn thi·∫øt<|eot_id|><|start_header_id|>user<|end_header_id>

C√¢u h·ªèi ng∆∞·ªùi d√πng: {query}

Th√¥ng tin t·ª´ c√°c agent:
{agent_responses}

Ng·ªØ c·∫£nh h·ªôi tho·∫°i tr∆∞·ªõc:
{context}

H√£y t·ªïng h·ª£p th√¥ng tin tr√™n v√† tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch r√µ r√†ng, h·ªØu √≠ch v·ªõi format d·ªÖ ƒë·ªçc.<|eot_id|><|start_header_id|>assistant<|end_header_id>

"""
            )

            self.general_chat_template = PromptTemplate(
                input_variables=["query", "context"],
                template="""<|begin_of_text|><|start_header_id|>system<|end_header_id>
Cutting Knowledge Date: December 2023 Today Date: 26 Jul 2024

B·∫°n l√† m·ªôt AI Assistant th√¢n thi·ªán v√† h·ªØu √≠ch. B·∫°n c√≥ th·ªÉ tr√≤ chuy·ªán v·ªÅ nhi·ªÅu ch·ªß ƒë·ªÅ kh√°c nhau m·ªôt c√°ch t·ª± nhi√™n v√† vui v·∫ª.

Nguy√™n t·∫Øc tr·∫£ l·ªùi:
- Tr·∫£ l·ªùi m·ªôt c√°ch t·ª± nhi√™n, th√¢n thi·ªán
- Cung c·∫•p th√¥ng tin h·ªØu √≠ch v√† ch√≠nh x√°c
- S·ª≠ d·ª•ng emoji ph√π h·ª£p ƒë·ªÉ l√†m cho cu·ªôc tr√≤ chuy·ªán sinh ƒë·ªông h∆°n
- Gi·ªØ phong c√°ch g·∫ßn g≈©i, d·ªÖ hi·ªÉu
- N·∫øu kh√¥ng bi·∫øt th√¥ng tin, h√£y th√†nh th·∫≠t n√≥i r·∫±ng kh√¥ng bi·∫øt

L∆∞u √Ω: B·∫°n c≈©ng c√≥ kh·∫£ nƒÉng h·ªó tr·ª£ theo d√µi s·ª©c kh·ªèe, n·∫øu ng∆∞·ªùi d√πng h·ªèi v·ªÅ s·ª©c kh·ªèe ho·∫∑c c√¥ng vi·ªác.<|eot_id|><|start_header_id|>user<|end_header_id>

C√¢u h·ªèi: {query}

Ng·ªØ c·∫£nh h·ªôi tho·∫°i tr∆∞·ªõc:
{context}

H√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch t·ª± nhi√™n v√† h·ªØu √≠ch.<|eot_id|><|start_header_id|>assistant<|end_header_id>

"""
            )

            self.synthesis_chain = LLMChain(
                llm=self.llm,
                prompt=self.synthesis_template
            )

            self.general_chat_chain = LLMChain(
                llm=self.llm,
                prompt=self.general_chat_template
            )

        except Exception as e:
            logger.error(f"L·ªói kh·ªüi t·∫°o LLM: {e}")
            raise RuntimeError(f"Kh√¥ng th·ªÉ kh·ªüi t·∫°o LLM: {e}")

    def generate_response(self, query: str, agent_responses: Dict = None, context: str = "",
                          use_general_chat: bool = False) -> str:
        """Sinh ph·∫£n h·ªìi t·ª´ th√¥ng tin c√°c agent ho·∫∑c chat chung"""

        if use_general_chat:
            return self._generate_general_chat_response(query, context)

        if not agent_responses:
            return self._generate_general_chat_response(query, context)

        if not self.synthesis_chain:
            return self._fallback_response(query, agent_responses)

        try:
            agent_info = []
            for agent_type, response in agent_responses.items():
                if response.success:
                    formatted_data = self._format_agent_data(agent_type, response.data)
                    agent_info.append(f"**{agent_type}**:\n{formatted_data}")
                else:
                    agent_info.append(f"**{agent_type}**: ‚ùå L·ªói - {response.error}")

            agent_responses_text = "\n\n".join(agent_info)

            response = self.synthesis_chain.run(
                query=query,
                agent_responses=agent_responses_text,
                context=context if context else "Kh√¥ng c√≥ ng·ªØ c·∫£nh tr∆∞·ªõc ƒë√≥."
            )

            formatted_response = self._format_final_response(response.strip())
            return formatted_response

        except Exception as e:
            logger.error(f"L·ªói sinh ph·∫£n h·ªìi: {e}")
            return self._fallback_response(query, agent_responses)

    def _generate_general_chat_response(self, query: str, context: str = "") -> str:
        """Sinh ph·∫£n h·ªìi cho chat chung"""
        try:
            if not self.general_chat_chain:
                return self._fallback_general_response(query)

            response = self.general_chat_chain.run(
                query=query,
                context=context if context else "Kh√¥ng c√≥ ng·ªØ c·∫£nh tr∆∞·ªõc ƒë√≥."
            )

            return self._format_final_response(response.strip())

        except Exception as e:
            logger.error(f"L·ªói sinh ph·∫£n h·ªìi chat chung: {e}")
            return self._fallback_general_response(query)

    def _fallback_general_response(self, query: str) -> str:
        """Ph·∫£n h·ªìi d·ª± ph√≤ng cho chat chung"""
        return f"ü§ñ T√¥i hi·ªÉu b·∫°n mu·ªën h·ªèi v·ªÅ: '{query}'\n\nT√¥i s·∫µn s√†ng tr√≤ chuy·ªán v·ªõi b·∫°n! Tuy nhi√™n, t√¥i chuy√™n v·ªÅ h·ªó tr·ª£ s·ª©c kh·ªèe v√† theo d√µi c√¥ng vi·ªác. B·∫°n c√≥ mu·ªën h·ªèi g√¨ v·ªÅ s·ª©c kh·ªèe ho·∫∑c th√≥i quen l√†m vi·ªác kh√¥ng? üòä"

    def _format_agent_data(self, agent_type: str, data: Dict) -> str:
        """Format d·ªØ li·ªáu t·ª´ agent ƒë·ªÉ d·ªÖ ƒë·ªçc"""
        if not data:
            return "Kh√¥ng c√≥ d·ªØ li·ªáu"

        formatted_parts = []

        if agent_type == "recommend_agent":
            if data.get("action") == "recommendations":
                if "alerts" in data:
                    alerts = data["alerts"]
                    if alerts:
                        formatted_parts.append("‚ö†Ô∏è **C·∫£nh b√°o:**")
                        for alert in alerts:
                            formatted_parts.append(f"  - {alert}")

                if "recommendations" in data:
                    recs = data["recommendations"]
                    if recs:
                        formatted_parts.append("\nüí° **Khuy·∫øn ngh·ªã:**")
                        for rec in recs:
                            formatted_parts.append(f"  - {rec}")

                if "current_status" in data:
                    status = data["current_status"]
                    formatted_parts.append(f"\nüìä **Tr·∫°ng th√°i hi·ªán t·∫°i:** {status}")

            elif data.get("action") == "started":
                formatted_parts.append(f"üîÑ {data.get('message', 'ƒê√£ b·∫Øt ƒë·∫ßu theo d√µi')}")

            elif data.get("action") == "stopped":
                formatted_parts.append(f"‚èπÔ∏è {data.get('message', 'ƒê√£ d·ª´ng theo d√µi')}")

            elif data.get("action") == "status_check":
                is_running = data.get("is_running", False)
                status_emoji = "‚úÖ" if is_running else "‚è∏Ô∏è"
                formatted_parts.append(
                    f"{status_emoji} **Tr·∫°ng th√°i h·ªá th·ªëng:** {'ƒêang ch·∫°y' if is_running else 'ƒê√£ d·ª´ng'}")

                if "health_status" in data:
                    health = data["health_status"]
                    formatted_parts.append(f"üè• **S·ª©c kh·ªèe:** {health}")

        elif agent_type == "retrieval_agent":
            if data.get("action") == "data_analysis":
                query_result = data.get("query_result", {})
                formatted_parts.append(f"üìä **K·∫øt qu·∫£ truy v·∫•n:** {query_result.get('results_count', 0)} b·∫£n ghi")
                formatted_parts.append(f"‚è±Ô∏è **Th·ªùi gian x·ª≠ l√Ω:** {query_result.get('query_time', 'N/A')}")

                if "analysis" in data:
                    analysis = data["analysis"]

                    if analysis.get("summary"):
                        formatted_parts.append(f"\nüìù **T√≥m t·∫Øt:** {analysis['summary']}")

                    if analysis.get("statistics"):
                        formatted_parts.append("\nüìà **Th·ªëng k√™:**")
                        stats = analysis["statistics"]
                        for key, value in stats.items():
                            formatted_parts.append(f"  - {key}: {value}")

                    if analysis.get("trends"):
                        formatted_parts.append("\nüìâ **Xu h∆∞·ªõng:**")
                        for trend in analysis["trends"]:
                            formatted_parts.append(f"  - {trend}")

                    if analysis.get("patterns"):
                        formatted_parts.append("\nüîç **M·∫´u th√≥i quen:**")
                        for pattern in analysis["patterns"]:
                            formatted_parts.append(f"  - {pattern}")

        return "\n".join(formatted_parts) if formatted_parts else json.dumps(data, ensure_ascii=False, indent=2)

    def _format_final_response(self, response: str) -> str:
        """Chu·∫©n h√≥a format ph·∫£n h·ªìi cu·ªëi c√πng"""
        response = response.strip()
        response = re.sub(r'\.([A-Z])', r'. \1', response)
        response = re.sub(r'(\*\*[^*]+\*\*)', r'\n\1\n', response)
        response = re.sub(r'\n\s*\n\s*\n', '\n\n', response)
        response = re.sub(r'\n\s*-\s*', '\n  - ', response)
        return response.strip()

    def _fallback_response(self, query: str, agent_responses: Dict) -> str:
        """Ph·∫£n h·ªìi d·ª± ph√≤ng khi LLM kh√¥ng ho·∫°t ƒë·ªông"""
        response_parts = ["ü§ñ **K·∫øt qu·∫£ x·ª≠ l√Ω:**\n"]

        for agent_type, response in agent_responses.items():
            if response.success:
                formatted_data = self._format_agent_data(agent_type, response.data)
                response_parts.append(f"‚úÖ **{agent_type}:**\n{formatted_data}\n")
            else:
                response_parts.append(f"‚ùå **{agent_type}:** Kh√¥ng th·ªÉ x·ª≠ l√Ω - {response.error}\n")

        return "\n".join(response_parts)


class MasterAgent:
    """Master Agent ch√≠nh ƒëi·ªÅu khi·ªÉn c√°c sub-agent v·ªõi kh·∫£ nƒÉng chat th√¥ng minh"""

    def __init__(self, model_path: str = "models/Llama-3.2-3B-Instruct-Q8_0.gguf"):
        """
        Kh·ªüi t·∫°o Master Agent
        Args:
            model_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn m√¥ h√¨nh LLM
        """
        self.intent_classifier = SmartIntentClassifier()
        self.llm_generator = LLMResponseGenerator(model_path)
        self.recommend_agent = None
        self.retrieval_agent = None
        self.conversation_history: List[BaseMessage] = []
        logger.info("Master Agent v·ªõi kh·∫£ nƒÉng chat th√¥ng minh ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o")

    def set_agents(self,
                   recommend_agent: Optional[Union[object, type]] = None,
                   retrieval_agent: Optional[Union[object, type]] = None):
        """
        Thi·∫øt l·∫≠p c√°c sub-agent.
        - N·∫øu truy·ªÅn v√†o instance, d√πng lu√¥n instance ƒë√≥.
        - N·∫øu truy·ªÅn v√†o class (Type), s·∫Ω kh·ªüi t·∫°o m·ªõi.
        - N·∫øu kh√¥ng truy·ªÅn g√¨, t·ª± import v√† kh·ªüi t·∫°o default.
        """
        if recommend_agent is None:
            try:
                self.recommend_agent = RecommendAgent(HealthDataCollector())
                logger.info("RecommendAgent m·∫∑c ƒë·ªãnh ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o.")
            except Exception as e:
                logger.error(f"Kh√¥ng th·ªÉ kh·ªüi t·∫°o RecommendAgent: {e}")
                self.recommend_agent = None
        else:
            if isinstance(recommend_agent, type):
                try:
                    self.recommend_agent = recommend_agent()
                    logger.info("RecommendAgent custom class ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o.")
                except Exception as e:
                    logger.error(f"Kh√¥ng th·ªÉ kh·ªüi t·∫°o RecommendAgent custom: {e}")
                    self.recommend_agent = None
            else:
                self.recommend_agent = recommend_agent
                logger.info("RecommendAgent custom instance ƒë√£ ƒë∆∞·ª£c g√°n.")

        if retrieval_agent is None:
            try:
                self.retrieval_agent = RetrievalAgent()
                logger.info("RetrievalAgent m·∫∑c ƒë·ªãnh ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o.")
            except Exception as e:
                logger.error(f"Kh√¥ng th·ªÉ kh·ªüi t·∫°o RetrievalAgent: {e}")
                self.retrieval_agent = None
        else:
            if isinstance(retrieval_agent, type):
                try:
                    self.retrieval_agent = retrieval_agent()
                    logger.info("RetrievalAgent custom class ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o.")
                except Exception as e:
                    logger.error(f"Kh√¥ng th·ªÉ kh·ªüi t·∫°o RetrievalAgent custom: {e}")
                    self.retrieval_agent = None
            else:
                self.retrieval_agent = retrieval_agent
                logger.info("RetrievalAgent custom instance ƒë√£ ƒë∆∞·ª£c g√°n.")

    async def process_query(self, query: str) -> str:
        """X·ª≠ l√Ω c√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng v·ªõi kh·∫£ nƒÉng routing th√¥ng minh"""
        try:
            user_query = UserQuery(
                text=query,
                timestamp=datetime.now()
            )
            intent_result = self.intent_classifier.classify_intent(query)
            user_query.intent = intent_result["reasoning"]
            logger.info(f"Ph√¢n lo·∫°i √Ω ƒë·ªãnh: {intent_result}")

            if intent_result["use_general_chat"]:
                logger.info("S·ª≠ d·ª•ng chat chung, kh√¥ng c·∫ßn sub-agent")
                final_response = self.llm_generator.generate_response(
                    query=query,
                    agent_responses=None,
                    context=self._get_conversation_context(),
                    use_general_chat=True
                )
                self.conversation_history.append(HumanMessage(content=query))
                self.conversation_history.append(AIMessage(content=final_response))
                return final_response

            status_message = self._create_status_message(intent_result)
            agent_responses = await self._call_agents(user_query, intent_result)

            if not any(response.success for response in agent_responses.values()):
                error_message = self._create_error_message(agent_responses)
                return f"{status_message}\n{error_message}"

            final_response = self.llm_generator.generate_response(
                query=query,
                agent_responses=agent_responses,
                context=self._get_conversation_context(),
                use_general_chat=False
            )

            self.conversation_history.append(HumanMessage(content=query))
            self.conversation_history.append(AIMessage(content=final_response))

            formatted_result = f"{status_message}\n---\n\n{final_response}"
            return formatted_result

        except Exception as e:
            logger.error(f"L·ªói x·ª≠ l√Ω c√¢u h·ªèi: {e}")
            return f"‚ùå **L·ªói h·ªá th·ªëng:** ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω c√¢u h·ªèi - {str(e)}\n\nVui l√≤ng th·ª≠ l·∫°i sau."

    async def _call_agents(self, user_query: UserQuery, intent_result: Dict) -> Dict[str, AgentResponse]:
        """G·ªçi c√°c sub-agent d·ª±a tr√™n √Ω ƒë·ªãnh"""
        responses = {}
        if intent_result["primary_agent"] == AgentType.RECOMMEND or intent_result["use_both"]:
            responses["recommend_agent"] = await self._call_recommend_agent(user_query)
        if (intent_result["primary_agent"] == AgentType.RETRIEVAL or
                intent_result["use_both"] or
                intent_result["secondary_agent"] == AgentType.RETRIEVAL):
            responses["retrieval_agent"] = await self._call_retrieval_agent(user_query)
        return responses

    async def _call_recommend_agent(self, user_query: UserQuery) -> AgentResponse:
        """G·ªçi recommend_agent"""
        try:
            if not self.recommend_agent:
                return AgentResponse(
                    success=False,
                    error="Recommend agent ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o",
                    agent_type=AgentType.RECOMMEND
                )

            query_lower = user_query.text.lower()

            if any(keyword in query_lower for keyword in ["start", "b·∫Øt ƒë·∫ßu", "kh·ªüi ƒë·ªông"]):
                if hasattr(self.recommend_agent, 'start'):
                    self.recommend_agent.start()
                    data = {"action": "started", "message": "ƒê√£ b·∫Øt ƒë·∫ßu theo d√µi s·ª©c kh·ªèe"}
                else:
                    data = {"action": "not_supported", "message": "Ch·ª©c nƒÉng start kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£"}
            elif any(keyword in query_lower for keyword in ["stop", "d·ª´ng", "t·∫Øt"]):
                if hasattr(self.recommend_agent, 'stop'):
                    self.recommend_agent.stop()
                    data = {"action": "stopped", "message": "ƒê√£ d·ª´ng theo d√µi s·ª©c kh·ªèe"}
                else:
                    data = {"action": "not_supported", "message": "Ch·ª©c nƒÉng stop kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£"}
            elif any(keyword in query_lower for keyword in ["status", "tr·∫°ng th√°i"]):
                status_data = {}
                if hasattr(self.recommend_agent, 'is_engine_running'):
                    status_data["is_running"] = self.recommend_agent.is_engine_running()
                if hasattr(self.recommend_agent, 'get_health_status'):
                    status_data["health_status"] = self.recommend_agent.get_health_status()
                data = {"action": "status_check", **status_data}
            else:
                if hasattr(self.recommend_agent, 'get_recommendations'):
                    data = self.recommend_agent.get_recommendations(include_analysis=True)
                    data["action"] = "recommendations"
                else:
                    data = {"action": "not_supported", "message": "Ch·ª©c nƒÉng get_recommendations kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£"}

            return AgentResponse(
                success=True,
                data=data,
                agent_type=AgentType.RECOMMEND
            )

        except Exception as e:
            logger.error(f"L·ªói g·ªçi recommend_agent: {e}")
            return AgentResponse(
                success=False,
                error=f"Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi recommend_agent: {str(e)}",
                agent_type=AgentType.RECOMMEND
            )

    async def _call_retrieval_agent(self, user_query: UserQuery) -> AgentResponse:
        """G·ªçi retrieval_agent"""
        try:
            if not self.retrieval_agent:
                return AgentResponse(
                    success=False,
                    error="Retrieval agent ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o",
                    agent_type=AgentType.RETRIEVAL
                )

            if not hasattr(self.retrieval_agent, 'retrieve_data'):
                return AgentResponse(
                    success=False,
                    error="Retrieval agent kh√¥ng c√≥ method retrieve_data",
                    agent_type=AgentType.RETRIEVAL
                )

            query_result = self.retrieval_agent.retrieve_data(
                query=user_query.text,
                max_results=10
            )

            if not query_result.results:
                return AgentResponse(
                    success=False,
                    error="Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ph√π h·ª£p v·ªõi c√¢u h·ªèi",
                    agent_type=AgentType.RETRIEVAL
                )

            analysis_result = None
            if hasattr(self.retrieval_agent, 'analyze_statistical_patterns'):
                analysis_result = self.retrieval_agent.analyze_statistical_patterns(
                    query=user_query.text,
                    data=query_result.results
                )

            data = {
                "action": "data_analysis",
                "query_result": {
                    "total_results": query_result.results,
                    "query_time": query_result.query_time,
                    "results_count": len(query_result.results)
                }
            }

            if analysis_result:
                data["analysis"] = {
                    "summary": analysis_result.summary,
                    "statistics": analysis_result.statistics,
                    "trends": analysis_result.trends,
                    "patterns": analysis_result.patterns
                }

            return AgentResponse(
                success=True,
                data=data,
                agent_type=AgentType.RETRIEVAL
            )

        except Exception as e:
            logger.error(f"L·ªói g·ªçi retrieval_agent: {e}")
            return AgentResponse(
                success=False,
                error=f"Kh√¥ng th·ªÉ ph√¢n t√≠ch d·ªØ li·ªáu: {str(e)}",
                agent_type=AgentType.RETRIEVAL
            )

    def _create_status_message(self, intent_result: Dict) -> str:
        """T·∫°o th√¥ng b√°o v·ªÅ vi·ªác s·ª≠ d·ª•ng agent"""
        if intent_result["use_both"]:
            return "ü§ñ **ƒêang x·ª≠ l√Ω:**\n  - Recommend Agent (c·∫£nh b√°o real-time)\n  - Retrieval Agent (ph√¢n t√≠ch d·ªØ li·ªáu)\n"
        elif intent_result["primary_agent"] == AgentType.RECOMMEND:
            return "ü§ñ **ƒêang s·ª≠ d·ª•ng Recommend Agent** ƒë·ªÉ l·∫•y c·∫£nh b√°o v√† khuy·∫øn ngh·ªã...\n"
        elif intent_result["primary_agent"] == AgentType.RETRIEVAL:
            return "ü§ñ **ƒêang s·ª≠ d·ª•ng Retrieval Agent** ƒë·ªÉ ph√¢n t√≠ch d·ªØ li·ªáu v√† xu h∆∞·ªõng...\n"
        else:
            return "ü§ñ **ƒêang x·ª≠ l√Ω c√¢u h·ªèi...**\n"

    def _create_error_message(self, agent_responses: Dict) -> str:
        """T·∫°o th√¥ng b√°o l·ªói"""
        error_parts = ["‚ùå **Kh√¥ng th·ªÉ x·ª≠ l√Ω c√¢u h·ªèi do c√°c l·ªói sau:**\n"]
        for agent_type, response in agent_responses.items():
            if not response.success:
                error_parts.append(f"  - **{agent_type}:** {response.error}")
        if len(error_parts) > 1:
            return "\n".join(error_parts)
        else:
            return "‚ùå **Kh√¥ng th·ªÉ x·ª≠ l√Ω c√¢u h·ªèi.** Vui l√≤ng th·ª≠ l·∫°i sau.\n"

    def _get_conversation_context(self) -> str:
        """L·∫•y ng·ªØ c·∫£nh h·ªôi tho·∫°i"""
        if len(self.conversation_history) > 4:
            recent_history = self.conversation_history[-4:]
        else:
            recent_history = self.conversation_history

        context_parts = []
        for message in recent_history:
            if isinstance(message, HumanMessage):
                context_parts.append(f"Ng∆∞·ªùi d√πng: {message.content}")
            elif isinstance(message, AIMessage):
                context_parts.append(f"Assistant: {message.content}")
        return "\n".join(context_parts)

    def reset_conversation(self):
        """ƒê·∫∑t l·∫°i l·ªãch s·ª≠ h·ªôi tho·∫°i"""
        self.conversation_history = []
        logger.info("ƒê√£ ƒë·∫∑t l·∫°i l·ªãch s·ª≠ h·ªôi tho·∫°i")

    def get_agent_status(self) -> Dict:
        """L·∫•y tr·∫°ng th√°i c·ªßa c√°c agent"""
        status = {
            "master_agent": "active",
            "recommend_agent": "not_connected",
            "retrieval_agent": "not_connected"
        }

        if self.recommend_agent:
            try:
                if hasattr(self.recommend_agent, 'is_engine_running'):
                    status[
                        "recommend_agent"] = "connected" if self.recommend_agent.is_engine_running() else "connected_but_stopped"
                else:
                    status["recommend_agent"] = "connected"
            except Exception as e:
                status["recommend_agent"] = f"error: {str(e)}"

        if self.retrieval_agent:
            try:
                if hasattr(self.retrieval_agent, 'get_health_status'):
                    health_status = self.retrieval_agent.get_health_status()
                    status["retrieval_agent"] = "connected" if health_status.get(
                        "status") == "healthy" else "connected_with_issues"
                else:
                    status["retrieval_agent"] = "connected"
            except Exception as e:
                status["retrieval_agent"] = f"error: {str(e)}"
        return status